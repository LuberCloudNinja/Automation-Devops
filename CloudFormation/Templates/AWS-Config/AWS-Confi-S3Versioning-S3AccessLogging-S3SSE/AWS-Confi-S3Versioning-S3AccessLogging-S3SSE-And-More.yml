AWSTemplateFormatVersion: 2010-09-09
Description: AWS Config Rules Version 2.0

Parameters:
    
  pSnsAlertNotifyEmail:
    Description:  SNS Topic for Config Alerts sent to piee-security@credence-llc.com
    Type: String


Resources:

  #####################################
  # Cloudwatch Event 
  #####################################
    
  CloudWatchEventRuleConfigViolations:
    Type: AWS::Events::Rule
    Properties:
      Description: "Event Rule to Watch for AWS Config Violations"
      EventPattern:
        source:
          - "aws.config"
        detail-type:
          - "Config Rules Compliance Change"
        detail:
          newEvaluationResult:
            complianceType:
              - "NON_COMPLIANT"
      State: "ENABLED"
      Targets:
        - Arn: !Ref rSnsAlertTopic
          Id: "rSnsAlertTopic"
          InputTransformer:
            InputPathsMap:
              resourceType: "$.detail.newEvaluationResult.evaluationResultIdentifier.evaluationResultQualifier.resourceType"
              resourceId: "$.detail.newEvaluationResult.evaluationResultIdentifier.evaluationResultQualifier.resourceId"
              configRuleName: "$.detail.newEvaluationResult.evaluationResultIdentifier.evaluationResultQualifier.configRuleName"
              region: "$.detail.awsRegion"
              accountID: "$.detail.awsAccountId"
              compliance: "$.detail.newEvaluationResult.complianceType"
              checkTime: "$.detail.newEvaluationResult.resultRecordedTime"
            InputTemplate: |
              "The resource <resourceType> <resourceId> in <region> <accountID> is <compliance> with rule <configRuleName> as of <checkTime>."


  #######################################
  #  SNS Resources
  #######################################
   
   
   # SNS Alert Topic
  rSnsAlertTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Alert-Topic

  # Email subscription for Alert topic
  rAlertNotifySubscription:
    Type: AWS::SNS::Subscription
    Properties:
      Endpoint: !Ref "pSnsAlertNotifyEmail"
      Protocol: email
      TopicArn: !Ref "rSnsAlertTopic"
    
  ConfigSNSTopicPolicy:
    Type: "AWS::SNS::TopicPolicy"
    Properties:
      PolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: events.amazonaws.com
            Action: "sns:Publish"
            Resource: "*"
      Topics:
        - !Ref rSnsAlertTopic



  LambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - arn:aws-us-gov:iam::aws:policy/IAMReadOnlyAccess
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:*'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: '*'
  S3LambdaToEnableVersioning:
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: index.lambda_handler
      Role:
        'Fn::GetAtt':
          - LambdaExecutionRole
          - Arn
      Runtime: python3.8
      Timeout: 180
      Code:
        ZipFile: |
          import json
          import boto3


          class EnableS3Versioning:
              def __init__(self):
                  self._s3 = boto3.client('s3')
                  self.all_buckets = []

              def list_buckets(self):
                  for buckets in self._s3.list_buckets()['Buckets']:
                      s3_buckets = buckets['Name']
                      self.all_buckets.append(s3_buckets)
              
              def enable_bucket_versioning(self):
                  for items in self.all_buckets:
                      versioning = self._s3.put_bucket_versioning(
                          Bucket=items,
                          VersioningConfiguration={
                              'Status': 'Enabled'
                              })
                  listing_them_all = [s3_enabled_version for s3_enabled_version in self.all_buckets]
                  for item in listing_them_all:
                      print(f"We eneabled versioning in bucket: '{item}'.")

          def lambda_handler(event, context):
              s3 = EnableS3Versioning()
              s3.list_buckets()
              s3.enable_bucket_versioning()

  #########################################
  #  Config Rules With Auto-Remediation
  ######################################### 

  ConfigRuleForS3:
    Type: 'AWS::Config::ConfigRule'
    DependsOn: S3LambdaToEnableVersioning
    Properties:
      ConfigRuleName: s3-bucket-versioning-enabled
      Description: >-
        Checks whether versioning is enabled for your S3 buckets. Optionally,
        the rule checks if MFA delete is enabled for your S3 buckets
      Scope:
        ComplianceResourceTypes:
          - 'AWS::S3::Bucket'
      Source:
        Owner: AWS
        SourceIdentifier: S3_BUCKET_VERSIONING_ENABLED

  CreateEventBridgeToTriggerLambdaVersioning:
    Type: AWS::Events::Rule
    Properties: 
      Description: Enable Version in all S3 Buckets.
      EventBusName: default
      EventPattern: {"source": ["aws.config"]}
      Name: AWS-Config-Auto-Remediation-S3-Versioning
      Targets: 
        - Arn: !GetAtt 
            - S3LambdaToEnableVersioning
            - Arn
          Id: S3LambdaToEnableVersioning

  PermissionForEventsToInvokeLambdaVersioning: 
    Type: AWS::Lambda::Permission
    Properties: 
      FunctionName: !Ref S3LambdaToEnableVersioning
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn: 
        Fn::GetAtt: 
          - CreateEventBridgeToTriggerLambdaVersioning
          - Arn      


  
  S3LambdaEnableAccessLogs:
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: index.lambda_handler
      Role:
        'Fn::GetAtt':
          - LambdaExecutionRole
          - Arn
      Runtime: python3.8
      Timeout: 180
      Code:
        ZipFile: |
          import json
          import boto3
          import datetime
          from botocore.exceptions import ClientError

          class EnableAccessLogging:
              def __init__(self, context):
                  self._s3_service_client_us_gov_west_1 = boto3.client("s3",region_name="us-gov-west-1")
                  self._s3_service_resource_us_gov_west_1 = boto3.resource("s3",region_name="us-gov-west-1")
                  self._iam_service_client_us_gov_west_1 = boto3.client("sts",region_name="us-gov-west-1")
                  self.get_lambda_region = context.invoked_function_arn[22:35]



              def list_all_buckets(self):
                  """ List all buckets and append them to a list """
                  self._all_buckets = [buckets['Name'] for buckets in self._s3_service_client_us_gov_west_1.list_buckets()['Buckets']]
                  for num, list_buckets in enumerate(self._all_buckets, start= 1):
                      print(f"{num}- {list_buckets}")
              
              def get_account_num(self):
                  """ Get account number """
                  self.account_number = self._iam_service_client_us_gov_west_1.get_caller_identity()['Account']
                  self.access_logs_bucket = f"access-logging-{self.account_number}"
              
              def get_bucket_location(self):
                  """ Get bucket region """  
                  for bucket_location in self._all_buckets:
                      self.bucket_region = self._s3_service_client_us_gov_west_1.get_bucket_location(Bucket= bucket_location)['LocationConstraint']


              def get_bucket_date_time(self):
                  """ Get date """
                  self.year = datetime.date.today().year
                  self.month = datetime.date.today().month
                  self.day = datetime.date.today().day
                
              def put_bucket_prefix(self):
                  for add_prefix in self._all_buckets:
                      if self.access_logs_bucket in add_prefix:
                          for bucket in self._all_buckets:
                              self._s3_service_client_us_gov_west_1.put_object(
                                  Bucket= self.access_logs_bucket,
                                  Key= f"awslogs/{self.account_number}/vpcflowlogs/{self.bucket_region}/{bucket}/{self.year}/{self.month}/{self.day}/"
                                  )
              def enable_access_logging(self):
                  """ Enable access loging in all buckets and send them to a target bucket """
                  bucket_acl = self._s3_service_resource_us_gov_west_1.BucketAcl(self.access_logs_bucket)
                  bucket_acl_grants = bucket_acl.grants
                  bucket_acl_grants.append(             
                          {
                              'Grantee': {
                                  'Type': 'Group',
                                  'URI': 'http://acs.amazonaws.com/groups/s3/LogDelivery'
                              },
                              'Permission': 'WRITE'
                          }
                          )
                                  
                  bucket_acl_grants.append(                
                          {
                              'Grantee': {
                                  'Type': 'Group',
                                  'URI': 'http://acs.amazonaws.com/groups/s3/LogDelivery'
                              },
                              'Permission': 'READ_ACP'
                          }
                          )
                  canonical_id = bucket_acl.owner['ID']
                  # The below exeption is if the bucket already has the ACL permission to ignore the "ClientError" and continue with the "put_bucket_logging()".
                  for check_acl_status in bucket_acl_grants:
                      try:
                          response = bucket_acl.put(
                              AccessControlPolicy={
                              'Grants': bucket_acl_grants,
                              'Owner': {
                                  'ID': canonical_id                
                              }})
                      except ClientError:
                          continue


                  for items in self._all_buckets:
                      use_to_compare_region = self._s3_service_client_us_gov_west_1.get_bucket_location(Bucket= items)['LocationConstraint']
                      if use_to_compare_region == self.get_lambda_region:
                          response = self._s3_service_client_us_gov_west_1.put_bucket_logging(
                              Bucket = items,
                              BucketLoggingStatus= {
                                  'LoggingEnabled': {
                                      'TargetBucket': self.access_logs_bucket,
                                      'TargetPrefix': f"awslogs/{self.account_number}/vpcflowlogs/{self.bucket_region}/{items}/{self.year}/{self.month}/{self.day}/"
                                  }
                              }
                          )


          def lambda_handler(event, context):
              object_1 = EnableAccessLogging(context)
              object_1.list_all_buckets()
              object_1.get_account_num()
              object_1.get_bucket_location()
              object_1.get_bucket_date_time()
              object_1.put_bucket_prefix()
              object_1.enable_access_logging()






  ConfigRuleForS3AccessLogs:
    Type: 'AWS::Config::ConfigRule'
    DependsOn: S3LambdaEnableAccessLogs
    Properties:
      ConfigRuleName: s3-bucket-logging-enabled
      Description: >-
        Checks whether access logging is enabled for your S3 buckets.
      Scope:
        ComplianceResourceTypes:
          - 'AWS::S3::Bucket'
      Source:
        Owner: AWS
        SourceIdentifier: S3_BUCKET_LOGGING_ENABLED

  CreateEventBridgeToTriggerLambdaForAccessLogging:
    Type: AWS::Events::Rule
    Properties: 
      Description: Enable Access Logging in all S3 Buckets.
      EventBusName: default
      EventPattern: {"source": ["aws.config"]}
      Name: AWS-Config-Auto-Remediation-S3-AccessLogging
      Targets: 
        - Arn: !GetAtt 
            - S3LambdaEnableAccessLogs
            - Arn
          Id: S3LambdaEnableAccessLogs

  PermissionForEventsToInvokeLambdaAccessLogging: 
    Type: AWS::Lambda::Permission
    Properties: 
      FunctionName: !Ref S3LambdaEnableAccessLogs
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn: 
        Fn::GetAtt: 
          - CreateEventBridgeToTriggerLambdaForAccessLogging
          - Arn
 
  # Create an AWS EventBridge that will trigger a lambda("S3LambdaEnableAccessLogs")
  # on a daily basics at 12am to put objects base on new reset prefix as year/month/date.

  CreateEventDailyPutPrefix:
    Type: AWS::Events::Rule
    Properties: 
      Description: Will run dailly as a cron expression to add new prefix to access-centralized-logging-xxxxxxx bucket.
      EventBusName: default
      Name: Add-Prefix-S3-Daily
      ScheduleExpression: cron(0 0 * * ? *)
      Targets: 
        - Arn: !GetAtt 
            - S3LambdaEnableAccessLogs
            - Arn
          Id: S3LambdaEnableAccessLogs

  InvokeLambdaAccessLoggingDaily: 
    Type: AWS::Lambda::Permission
    Properties: 
      FunctionName: !Ref S3LambdaEnableAccessLogs
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn: 
        Fn::GetAtt: 
          - CreateEventDailyPutPrefix
          - Arn
      


  S3LambdaEnableSSE:
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: index.lambda_handler
      Role:
        'Fn::GetAtt':
          - LambdaExecutionRole
          - Arn
      Runtime: python3.8
      Timeout: 180
      Code:
        ZipFile: |
          import json
          import boto3

          def lambda_handler(event, context):
              s3_buckets = boto3.client("s3")
              all_buckets = []
              
              for buckets in s3_buckets.list_buckets()['Buckets']:
                  all_buckets.append(buckets['Name'])
                  
              for items in all_buckets:
                  response = s3_buckets.put_bucket_encryption(
              Bucket=items,
                  ServerSideEncryptionConfiguration={
                  'Rules': [
                      {
                          'ApplyServerSideEncryptionByDefault': {
                              'SSEAlgorithm': 'AES256'
                          },
                          'BucketKeyEnabled': False
                      },
                  ]
              },)

  ConfigRuleForS3SSE:
    Type: 'AWS::Config::ConfigRule'
    DependsOn: S3LambdaEnableSSE
    Properties:
      ConfigRuleName: s3-bucket-server-side-encryption-enabled
      Description: >-
        Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-
        object requests without server side encryption that uses AES-256 or AWS Key Management Service.
      Scope:
        ComplianceResourceTypes:
          - 'AWS::S3::Bucket'
      Source:
        Owner: AWS
        SourceIdentifier: S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED

  CreateEventBridgeToTriggerLambdaForS3SSE:
    Type: AWS::Events::Rule
    Properties: 
      Description: Enable SSE in all S3 Buckets.
      EventBusName: default
      EventPattern: {"source": ["aws.config"]}
      Name: AWS-Config-Auto-Remediation-S3-SSE
      Targets: 
        - Arn: !GetAtt 
            - S3LambdaEnableSSE
            - Arn
          Id: S3LambdaEnableSSE

  PermissionForEventsToInvokeLambdaS3SSE:
    Type: AWS::Lambda::Permission
    Properties: 
      FunctionName: !Ref S3LambdaEnableSSE
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn: 
        Fn::GetAtt: 
          - CreateEventBridgeToTriggerLambdaForS3SSE
          - Arn

  # WE NEED TO CONFIGRE A LAMBDA AND EVENTBRIDGE FOR AUTO-REMEDIATION.
  ConfigRuleVpcFlowlogsEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "VPC_FLOW_LOGS_ENABLED"



  #########################################
  #  Config Rules Without Auto-Remediation
  #########################################

  ConfigRuleRDSNoPublicInstance:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "RDS_INSTANCE_PUBLIC_ACCESS_CHECK"


  ConfigRuleS3BucketSSLRequestsOnly:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "S3_BUCKET_SSL_REQUESTS_ONLY"


  ConfigRuleRDSSnapshotPublicProhibited:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "RDS_SNAPSHOTS_PUBLIC_PROHIBITED"


  ConfigRuleCloudTrailEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "CLOUD_TRAIL_CLOUD_WATCH_LOGS_ENABLED"


  ConfigRuleCloudTrailEncryptedEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "CLOUD_TRAIL_ENCRYPTION_ENABLED"


  ConfigRuleCloudTrailEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "CLOUD_TRAIL_ENABLED"


  ConfigRuleS3BucketPublicWriteProphibited:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "S3_BUCKET_PUBLIC_WRITE_PROHIBITED"


  ConfigRuleS3BucketPublicReadProhibited:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "S3_BUCKET_PUBLIC_READ_PROHIBITED"


  ConfigRuleCloudTrailLogFileValidationEnabled: 
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "CLOUD_TRAIL_LOG_FILE_VALIDATION_ENABLED"


  ConfigRuleCloudTrailS3DataEventsEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "CLOUDTRAIL_S3_DATAEVENTS_ENABLED" 


  ConfigRuleEBSSnapshotPublicRestorableCheck:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "EBS_SNAPSHOT_PUBLIC_RESTORABLE_CHECK"  


  ConfigRuleEC2EBSEncryptionByDefault:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "EC2_EBS_ENCRYPTION_BY_DEFAULT"  


  ConfigRuleEC2InstanceNoPublicIP:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "EC2_INSTANCE_NO_PUBLIC_IP"


  ConfigRuleELBDeletionProtectionEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier:  "ELB_DELETION_PROTECTION_ENABLED"


  ConfigRuleELBLoggingEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "ELB_LOGGING_ENABLED" 


  ConfigRuleEncryptedVolumes:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "ENCRYPTED_VOLUMES"


  ConfigRuleGuarddutyEnabledCentralized:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "GUARDDUTY_ENABLED_CENTRALIZED"


  ConfigRuleIAMPasswordPolicy:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "IAM_PASSWORD_POLICY"


  ConfigRuleIAMRootAccessKeyCheck:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "IAM_ROOT_ACCESS_KEY_CHECK"


  ConfigRuleIAMUserMFAEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "IAM_USER_MFA_ENABLED"


  ConfigRuleInternetGatewayAuthorizedVPCOnly:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS" 
        SourceIdentifier: "INTERNET_GATEWAY_AUTHORIZED_VPC_ONLY"

        
  ConfigRuleLambdaFunctionPublicAccessProhibited:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "LAMBDA_FUNCTION_PUBLIC_ACCESS_PROHIBITED"


  ConfigRuleMFAEnaledForIAMConsoleAccess:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "MFA_ENABLED_FOR_IAM_CONSOLE_ACCESS"


  ConfigRuleMultiRegionCloudTrailEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "MULTI_REGION_CLOUD_TRAIL_ENABLED"


  ConfigRuleRDSLoggingEnabled:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "RDS_LOGGING_ENABLED"


  ConfigRuleRDSSnapShotEncrypted:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "RDS_SNAPSHOT_ENCRYPTED"


  ConfigRuleRDSStorageEncrypted:
    Type: "AWS::Config::ConfigRule"
    Properties:
      Source:
        Owner: "AWS"
        SourceIdentifier: "RDS_STORAGE_ENCRYPTED"


  ConfigRuleAccessKeysRotated:
   Type: "AWS::Config::ConfigRule"
   Properties:
     Source:
       Owner: "AWS"
       SourceIdentifier: "ACCESS_KEYS_ROTATED"
     InputParameters:
        maxAccessKeyAge: '60'
                                                                                                                                   